import techminer as tech

##
## Converts scopus.csv to techminer.csv
##
tech.import_scopus()


import techminer as tech

##
## Creates or modifies the keywords thesaurus.txt
##   Honors previous created file
##
tech.create_keywords_thesaurus()

get_ipython().getoutput("head -n +20 keywords_thesaurus.txt")


import pandas as pd

data = pd.read_csv('techminer.csv')

for i in range(20):
    print('**** *doc{}'.format(i))
    print(data.Abstract[i])
    print('')
    print('')



import nltk
nltk.pos_tag(["the", "findings", "are", "unique", "carriers"])


import nltk
nltk.pos_tag(["findings"])


import nltk
nltk.download('tagsets')
nltk.help.upenn_tagset()


import pandas as pd

data = pd.read_csv('techminer.csv')
for s in data.Abstract[0:10]:
    print(s.lower())
    print()
    
import pandas as pd

data = pd.read_csv('scopus.csv')
data = data[0:10]
data.to_csv('scopus_.csv', index=False)


import pandas as pd

data = pd.read_csv('techminer.csv')
for s in data.Abstract_words_CL:
    print(s)



from nltk.stem import WordNetLemmatizer

wordnet_lemmatizer = WordNetLemmatizer()
wordnet_lemmatizer.lemmatize("activities", "v")


import nltk
nltk.__version__


from textblob import Word
Word('areas').singularize()


import pandas as pd

data = pd.read_csv('techminer.csv')
for s in data.Abstract_words:
    print(s)
    print()


import techminer as tech

##
## Keywords cleaning
##
tech.apply_keywords_thesaurus()


import techminer as tech

##
## Creates a Institutions thesaurus
##
tech.create_institutions_thesaurus()

get_ipython().getoutput("head -n +10 institutions_thesaurus.txt")


import techminer as tech

##
## Institutions cleaning
##
tech.apply_institutions_thesaurus()


import techminer as tech
##
## Coverage
##
tech.coverage()


import techminer as tech

##
## Descriptive stats
##
tech.descriptive_stats()


import techminer as tech

##
## Column explorer
##
tech.column_explorer(top_n=50, only_abstract=True)


import techminer as tech

##
## Matrix explorer
##
tech.matrix_explorer(top_n=50, only_abstract=True)


import techminer as tech

##
## Document-term
##
tech.document_term_analysis()


import techminer as tech

##
## By year analysis
##
tech.by_year_analysis()


import techminer as tech

##
## Top documents report
##
tech.top_documents(top_n=10)


import techminer as tech

##
## By term analysis
##
tech.by_term_analysis(limit_to=None, exclude=None, years_range=None)


import techminer as tech

##
## By-term-per-year
##
tech.by_term_per_year_analysis(
    tab=0, years_range=None
)


import techminer as tech

##
## Growth indicators
##
tech.growth_indicators(exclude=None, years_range=None)


import techminer as tech

##
## Bigraph
##
tech.bigraph_analysis()


import techminer as tech

##
## Graph
##
tech.graph_analysis(exclude=None)


import techminer as tech

##
## Correlation
##
tech.correlation_analysis()


import techminer as tech

##
## Factor Analysis
##
tech.factor_analysis()


import techminer as tech

##
## Concept Mapping
##
tech.concept_mapping()


import techminer as tech

##
## Latent Semantic Analysis
##
tech.latent_semantic_analysis()


import techminer as tech

##
## Comparative Analysis
##
tech.comparative_analysis()


import techminer as tech

##
## Thematic Analysis
##
tech.thematic_analysis()


##
## Limit to ... / Exclude ...
##
LIMIT_TO = {
    "Author_Keywords": text.find_string(
        patterns="^g",
        x=df.Author_Keywords,
        ignore_case=True,
        full_match=False,
        use_re=True,
    ),
    "Countries": ["United States"],
}

EXCLUDE = {
    "Author_Keywords": text.find_string(
        patterns="^g",
        x=df.Author_Keywords,
        ignore_case=True,
        full_match=False,
        use_re=True,
    ),
    "Countries": ["United States"],
    "Authors": ["Utzinger J", "Polling B"],
}



