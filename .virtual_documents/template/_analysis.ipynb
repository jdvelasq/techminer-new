##
## load_scopus
##
import pandas as pd

from techminer.load_scopus import load_scopus

load_scopus(pd.read_csv("scopus.csv")).to_csv("scopus-cleaned.csv", index=False)


##
## Thesaurus generation
##
import pandas as pd

import techminer.thesaurus as thesaurus

thesaurus.text_clustering(
    pd.Series( pd.read_csv("scopus-cleaned.csv").Author_Keywords.tolist())
).to_textfile("words-raw.txt")

get_ipython().getoutput("head -n +10 words-raw.txt")


##
## Cleaning using the thesaurus
##
import pandas as pd

import techminer.thesaurus as thesaurus
from techminer.map import map_

df = pd.read_csv("scopus-cleaned.csv")
th = thesaurus.read_textfile("words-cleaned.txt")

th = th.compile_as_dict()

df["Author_Keywords_CL"] = map_(df, "Author_Keywords", th.apply_as_dict)

df.to_csv("scopus-cleaned.csv", index=False)


##
## Top documents
##
import pandas as pd

df = pd.read_csv("scopus-cleaned.csv")
df = df.sort_values("Times_Cited", ascending=False).head(10)
df = df.reset_index(drop=True)
for i in range(len(df)):
    print(
        df.Authors[i].replace(";", ", ")
        + ". "
        + str(df.Year[i])
        + ". "
        + df.Title[i]
        + "\t"
        + str(int(df.Times_Cited[i]))
    )


##
## Coverage
##
import pandas as pd

from techminer.coverage import coverage

coverage(pd.read_csv("scopus-cleaned.csv"))


##
## Descriptive stats
##
import pandas as pd

from techminer.descriptive_stats import descriptive_stats

descriptive_stats(pd.read_csv("scopus-cleaned.csv"))


##
## Column viewer
##
import pandas as pd

import techminer.column_explorer as column_explorer

column_explorer.app(pd.read_csv("scopus-cleaned.csv"), top_n=None, only_abstract=True)


##
## Matrix viewer
##
import pandas as pd

import techminer.matrix_explorer as matrix_explorer

matrix_explorer.app(pd.read_csv("scopus-cleaned.csv"), top_n=50, only_abstract=True)


##
## Words to exclude
##


LIMIT_TO = {
    "Author_Keywords_CL": [    
        "adaptive dynamic programming",
        "agent-based modelling",
        "collaborative urban logistics",
        "customer service",
        "decision making",
        "discrete event simulation",
        "e-commerce",
        "game theory",
        "geographic information systems (gis)",
        "green vehicle",
        "greenhouse gas emissions",
        "key performance indicators",
        "last mile delivery",
        "linear programming",
        "location",
        "location routing problem",
        "metaheuristics",
        "mobile depot",
        "multi-criteria decision analysis (mcda)",
        "network logistics",
        "optimization",
        "parcel delivery",
        "parcel locker",
        "performance evaluation",
        "sensitivity analysis",
        "smart cities",
        "social cost benefit analysis",
        "stakeholder analysis",
        "sustainability",
        "sustainable urban freight transport",
        "vehicle routing problem",
    ],
    "Countries":[
        "Italy",
        "China",
        "France",
        "Netherlands",
        "United Kingdom",
        "Belgium",
        "United States",
        "Spain",
        "Australia",
        "Germany",
    ],
    "Authors": [
        "Allen J",
        "Awasthi A",
        "Browne M",
        "Chauhan SS",
        "Dablanc L",
        "Goyal SK",
        "Lebeau P",
        "Leonardi J",
        "Macharis C",
        "Quak HJ",
        "Qureshi AG",
        "Taniguchi E",
        "van Duin R",
        "van Mierlo J",
        "Woodburn A",

    ],
    
}

EXCLUDE = {
    "Author_Keywords_CL": [
        "business model",
        "case studies",
        "cities",
        "distribution",
        "entropy",
        "freight consolidation",
        "literature review",
        "logistics engineering",
        "logistics sprawl",
        "logistics",
        "micro-consolidation",
        "modelization",
        "policy evaluation",
        "retailer",
        "urban consolidation center",
        "urban freight transport",
        "urban freight",
        "urban logistic",
        "logistic system",
    ]
}


import pandas as pd

sorted(pd.read_csv('scopus-cleaned.csv').columns.tolist())


##
## Document-term
##
import pandas as pd

import techminer.document_term_analysis as document_term_analysis

document_term_analysis.app(pd.read_csv("scopus-cleaned.csv"))


##
## By year analysis
##
import pandas as pd

import techminer.by_year_analysis as by_year_analysis

by_year_analysis.app(pd.read_csv("scopus-cleaned.csv"))


##
## By-term
##
import pandas as pd

import techminer.by_term_analysis as by_term_analysis

by_term_analysis.app(pd.read_csv("scopus-cleaned.csv"), exclude=None, years_range=None)


##
## By-term-per-year
##
import pandas as pd

import techminer.by_term_per_year_analysis as by_term_per_year_analysis


by_term_per_year_analysis.app(
    pd.read_csv("scopus-cleaned.csv"), tab=0, limit_to=LIMIT_TO, years_range=None
)


##
## Growth indicators
##
import pandas as pd

import techminer.growth_indicators as growth_indicators


growth_indicators.app(pd.read_csv("scopus-cleaned.csv"), limit_to=LIMIT_TO, years_range=None)


##
## Bigraph
##
import pandas as pd

import techminer.bigraph_analysis as bigraph_analysis

bigraph_analysis.app(pd.read_csv("scopus-cleaned.csv"), limit_to=LIMIT_TO)


##
## Graph
##
import pandas as pd

import techminer.graph_analysis as graph_analysis

graph_analysis.app(pd.read_csv("scopus-cleaned.csv"), limit_to=LIMIT_TO)


##
## Correlation
##
import pandas as pd

import techminer.correlation as correlation

correlation.app(pd.read_csv("scopus-cleaned.csv"))


##
## Factor Analysis
##
import pandas as pd

import techminer.factor_analysis as factor_analysis

factor_analysis.app(pd.read_csv("scopus-cleaned.csv"), limit_to=LIMIT_TO)


##
## Latent Semantic Analysis
##
import pandas as pd

import techminer.latent_semantic_analysis as latent_semantic_analysis

latent_semantic_analysis.app(pd.read_csv("scopus-cleaned.csv"), limit_to=LIMIT_TO)


##
## Comparative Analysis
##
import pandas as pd

import techminer.comparative_analysis as comparative_analysis

comparative_analysis.app(pd.read_csv("scopus-cleaned.csv"), limit_to=LIMIT_TO)


##
## Thematic Analysis
##
import pandas as pd

import techminer.thematic_analysis as thematic_analysis

thematic_analysis.app(pd.read_csv("scopus-cleaned.csv"), limit_to=LIMIT_TO)


##
## Concept Mapping
##
import pandas as pd

import techminer.concept_mapping as concept_mapping

concept_mapping.app(pd.read_csv("scopus-cleaned.csv"), limit_to=LIMIT_TO)






