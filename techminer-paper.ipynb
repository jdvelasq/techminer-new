{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install latest version from GitHub\n",
    "!pip install -q -U git+https://github.com/jdvelasq/techminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from techminer import (\n",
    "    DataFrame,\n",
    "    Plot,\n",
    "    Thesaurus,\n",
    "    extract_country,\n",
    "    heatmap,\n",
    "    text_clustering,\n",
    "    text_nesting,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3553 entries, 0 to 3552\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Authors                    3553 non-null   object \n",
      " 1   Author(s) ID               3553 non-null   object \n",
      " 2   Title                      3553 non-null   object \n",
      " 3   Year                       3553 non-null   int64  \n",
      " 4   Source title               3553 non-null   object \n",
      " 5   Volume                     3553 non-null   int64  \n",
      " 6   Issue                      3553 non-null   int64  \n",
      " 7   Art. No.                   3067 non-null   float64\n",
      " 8   Page start                 3525 non-null   float64\n",
      " 9   Page end                   3498 non-null   float64\n",
      " 10  Page count                 11 non-null     float64\n",
      " 11  Cited by                   2452 non-null   float64\n",
      " 12  DOI                        3538 non-null   object \n",
      " 13  Link                       3553 non-null   object \n",
      " 14  Affiliations               3509 non-null   object \n",
      " 15  Authors with affiliations  3541 non-null   object \n",
      " 16  Author Keywords            3347 non-null   object \n",
      " 17  Index Keywords             3493 non-null   object \n",
      " 18  Document Type              3553 non-null   object \n",
      " 19  Publication Stage          3553 non-null   object \n",
      " 20  Access Type                55 non-null     object \n",
      " 21  Source                     3553 non-null   object \n",
      " 22  EID                        3553 non-null   object \n",
      "dtypes: float64(5), int64(3), object(15)\n",
      "memory usage: 638.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/jdvelasq/techminer/master/data/\"\n",
    "    + \"ieee-latin-america.csv\"\n",
    ")\n",
    "\n",
    "df = df.applymap(lambda x: None if pd.isna(x) is True else x)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3553"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Number of records\n",
    "#\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3D modeling;Bottleneck identifications;Computa...\n",
       "1    Combinated Models;Combinatorial Network of Dyn...\n",
       "2    Accident prevention strategies;Critical system...\n",
       "3    Distribution system;Distribution systems;Elect...\n",
       "4    Assistive Technology;Contact surface;Digital s...\n",
       "Name: Keywords, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Keywords merging\n",
    "#\n",
    "df = DataFrame(df).keywords_fusion()\n",
    "df.Keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Number of records without Keywords\n",
    "#\n",
    "len(df[df.Keywords.map(lambda x: x is None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84      Guest Editorial Special Issue on Embedded Systems\n",
       "99         Editorial IEEE Latin America Transactions 2020\n",
       "310     Guest Editorial Special Issue on Embedded Systems\n",
       "374        Editorial IEEE Latin America transactions 2019\n",
       "480                        Editorial to the regular issue\n",
       "702     The SimuroSot Strategy Development Kit: A high...\n",
       "738     Erratum: Towards a methodology of business pro...\n",
       "772                        Editorial to the regular issue\n",
       "1144                       Editorial to the regular issue\n",
       "2767    IEEE Latin America transactions volume 10 Issu...\n",
       "3107    7th International Information and Telecommunic...\n",
       "3112    13th Conference on Software Engineering and Da...\n",
       "3192    12th Conference of Software Engineering and Da...\n",
       "3210    Iberoamerican Workshop on Requirements Enginee...\n",
       "3211    4th International Workshop on Practical Applic...\n",
       "3287    6th Conference on Telematics Engineering, JITE...\n",
       "3310    Congress of Electronics, Robotics and Automoti...\n",
       "3312    11th Conference of Engineering Software and Da...\n",
       "3362    WTA 2007 - Adaptive technology tutorial [Adapt...\n",
       "3387    10th Jornadas de Ingenieria del Software y Bas...\n",
       "3399    Sixth Conference on Power, Instrumentation and...\n",
       "3401    6th Conference on Power, Instrumentation and M...\n",
       "3447    Tenth Meeting of Software and Database Enginee...\n",
       "3462    9th Jornadas de Ingenieria del Software y Base...\n",
       "3507    IEEE Latin America Transactions: Introduction ...\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Titles of documents without keywords\n",
    "#\n",
    "df[df.Keywords.map(lambda x: x is None)]['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Delete of records without keywords\n",
    "#\n",
    "df = df[df.Keywords.map(lambda x: x is not None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3528"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Number of selected records\n",
    "#\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 498/8342 [00:07<02:03, 63.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3c6bbcf3cf8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#   Keyword strings with the same number of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mthesaurus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thesaurus-text-clustering-raw.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthesaurus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/techminer/techminer/thesaurus.py\u001b[0m in \u001b[0;36mtext_clustering\u001b[0;34m(x, name_strategy, search_strategy, sep, transformer, min_cluster_size)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Text clustering of keywords.\n",
    "#   Keyword strings with the same number of words\n",
    "#\n",
    "thesaurus = text_clustering(df.Keywords, sep=\";\", transformer=lambda x: x.lower())\n",
    "with open(\"thesaurus-text-clustering-raw.json\", \"w\") as f:\n",
    "    f.write(thesaurus.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'ab', 'abc']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.Series(['abc', 'ab', 'a']).tolist()\n",
    "sorted(x, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Loads the new dictionary\n",
    "#\n",
    "with open(\"thesaurus-text-clustering-cleaned.json\", \"r\") as f:\n",
    "    dictionary = json.loads(f.read())\n",
    "    \n",
    "#\n",
    "#   Loads the new thesaurus\n",
    "#\n",
    "thesaurus = Thesaurus(dictionary, ignore_case=False, full_match=True, use_re=False)\n",
    "\n",
    "#\n",
    "#   Clean the Keywords\n",
    "#\n",
    "thesaurus.compile()\n",
    "df['Keywords'] = df.Keywords.map(lambda x: thesaurus.apply_as_dict(x, sep=\";\"))\n",
    "# thesaurus_dict = thesaurus.to_dict()\n",
    "#Â df['Keywords'] = df.Keywords.map(lambda x: ';'.join([thesaurus_dict[w] if w in thesaurus_dict.keys() else w for w in x.split(';')]))\n",
    "\n",
    "\n",
    "#\n",
    "#   Remove extra blanks between keywords if exists\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(\n",
    "    lambda x: \";\".join(set([w.strip() for w in x.split(\";\")]))\n",
    ")\n",
    "\n",
    "#\n",
    "#   Replace empty strings by None\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(lambda x: x if x != \"\" else None)\n",
    "\n",
    "#\n",
    "#   Number of unique of strings\n",
    "#\n",
    "len(\n",
    "    set([w.strip() for x in df.Keywords if x is not None for w in x.split(\";\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Text nesting\n",
    "#\n",
    "thesaurus = text_nesting(df.Keywords, sep=';', max_distance=1, transformer=lambda x: x.lower())\n",
    "\n",
    "#\n",
    "# Creates a thesaurus with candidate substrings as a thesaurus\n",
    "#\n",
    "with open('thesaurus-text-nesting-raw.json', 'w') as f:\n",
    "    f.write(tn.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Loads the new dictionary\n",
    "#\n",
    "with open(\"thesaurus-text-nesting-cleaned.json\", \"r\") as f:\n",
    "    dictionary = json.loads(f.read())\n",
    "    \n",
    "#\n",
    "#   Loads the new thesaurus\n",
    "#\n",
    "thesaurus = Thesaurus(dictionary, ignore_case=False, full_match=True, use_re=False)\n",
    "\n",
    "#\n",
    "# Apply the thesaurus\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(\n",
    "    lambda x: thesaurus.apply(x, sep=\";\")\n",
    ")\n",
    "\n",
    "#\n",
    "# Remove extra blanks between keywords\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(\n",
    "    lambda x: \";\".join(set([w.strip() for w in x.split(\";\")]))\n",
    ")\n",
    "\n",
    "#\n",
    "# Replace empty strings by None\n",
    "#\n",
    "df[\"Keywords\"] = df.Keywords.map(\n",
    "    lambda x: x if x != \"\" else None\n",
    ")\n",
    "\n",
    "#\n",
    "# Number of unique keywords\n",
    "#\n",
    "len(\n",
    "    set(\n",
    "        [w.strip() for x in df.Keywords if x is not None for w in x.split(\";\")]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# A column for identify each record is added to the dataframe.\n",
    "#\n",
    "\n",
    "\n",
    "df = DataFrame(df).generate_ID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Number of terms\n",
    "#\n",
    "df.count_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Author desambiguation\n",
    "#\n",
    "df = DataFrame(df).disambiguate_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Top 10 most frequent authors\n",
    "#\n",
    "sorted(df.documents_by_term('Authors').head(10).Authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Top 10 most cited authors\n",
    "#\n",
    "sorted(df.citations_by_term('Authors').head(10).Authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Top 10 most frequent keywords\n",
    "#\n",
    "df.documents_by_term(\"Keywords\", sep=\";\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Top 10 most cited keywords\n",
    "#\n",
    "df.citations_by_term(\"Keywords\", sep=\";\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Documents by year\n",
    "#\n",
    "\n",
    "\n",
    "Plot(df.documents_by_year()).bar(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Cumulative number of documents by year\n",
    "#\n",
    "Plot(df.documents_by_year(cumulative=True)).barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Worldmap with the number of documents by country\n",
    "#\n",
    "df[\"Country\"] = df[\"Affiliations\"].map(lambda x: extract_country(x, sep=\";\"))\n",
    "plt.figure(figsize=(12,5))\n",
    "Plot(df.documents_by_term(\"Country\", sep=\";\")).worldmap()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
